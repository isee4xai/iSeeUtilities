{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d89e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from enum import Enum\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44284a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('explainers.csv', delimiter=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd5b6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.read_csv('detail_with_weight.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56a24e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix.set_index('explainer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3fdd6",
   "metadata": {},
   "source": [
    "### Natural language explanations about similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf24935b",
   "metadata": {},
   "source": [
    "#### Formatting the attributes into readable language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3fb60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(row):\n",
    "    formatted = \"\"\n",
    "    if '#' in row:\n",
    "        formatted = row.split(\"#\",1)[1]\n",
    "    else:\n",
    "        formatted = row.rsplit(\"/\",1)[1]\n",
    "        \n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2076a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_format_text(row):\n",
    "    return format_text(row)[:-1]#.replace(\"_\", \"/\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55981bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_format_text(row, isBackend=False):\n",
    "    row_list = list(row.replace('[','').replace(']','').replace(' ','').split(','))\n",
    "    formatted = list()\n",
    "    for i in row_list:\n",
    "        formatted.append(format_text(i))\n",
    "    \n",
    "    if isBackend == True: \n",
    "        formatted = [x[:-1] for x in formatted]\n",
    "\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ea74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_complex_format_text(row):\n",
    "    row_list = row[:-2].replace('[','').split('], ')\n",
    "    formatted = list()\n",
    "    for elem in row_list:\n",
    "        formatted.append(complex_format_text(elem))\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3493aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f83992c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_df['ExplainabilityTechnique'] = formatted_df['ExplainabilityTechnique'].apply(lambda row: simple_format_text(row))\n",
    "formatted_df['DatasetType'] = formatted_df['DatasetType'].apply(lambda row: simple_format_text(row))\n",
    "formatted_df['Concurrentness'] = formatted_df['Concurrentness'].apply(lambda row: simple_format_text(row))\n",
    "formatted_df['Scope'] = formatted_df['Scope'].apply(lambda row: simple_format_text(row))\n",
    "formatted_df['Portability'] = formatted_df['Portability'].apply(lambda row: simple_format_text(row))\n",
    "formatted_df['TargetType'] = formatted_df['TargetType'].apply(lambda row: simple_format_text(row))\n",
    "formatted_df['Complexity'] = formatted_df['Complexity'].apply(lambda row: simple_format_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d23f7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_df['ExplainabilityTechniqueType'] = formatted_df['ExplainabilityTechniqueType'].apply(lambda row: complex_format_text(row))\n",
    "formatted_df['ExplanationType'] = formatted_df['ExplanationType'].apply(lambda row: complex_format_text(row))\n",
    "formatted_df['Backend'] = formatted_df['Backend'].apply(lambda row: complex_format_text(row, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25529c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_df['OutputType'] = formatted_df['OutputType'].apply(lambda row: array_complex_format_text(row))\n",
    "formatted_df['AIMethodType'] = formatted_df['AIMethodType'].apply(lambda row: array_complex_format_text(row))\n",
    "formatted_df['AITaskType'] = formatted_df['AITaskType'].apply(lambda row: array_complex_format_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4501d1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explainer</th>\n",
       "      <th>ExplainabilityTechnique</th>\n",
       "      <th>ExplainabilityTechniqueType</th>\n",
       "      <th>DatasetType</th>\n",
       "      <th>Concurrentness</th>\n",
       "      <th>Scope</th>\n",
       "      <th>Portability</th>\n",
       "      <th>TargetType</th>\n",
       "      <th>OutputType</th>\n",
       "      <th>ExplanationType</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>AIMethodType</th>\n",
       "      <th>AITaskType</th>\n",
       "      <th>Backend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Tabular/TreeSHAPGlobal</td>\n",
       "      <td>_Tabular_TreeSHAPGlobal_technique</td>\n",
       "      <td>[SHAP, Game_Theory_Technique, Feature_Relevance]</td>\n",
       "      <td>multivariate</td>\n",
       "      <td>post-hoc</td>\n",
       "      <td>global</td>\n",
       "      <td>modelSpecific</td>\n",
       "      <td>model</td>\n",
       "      <td>[[SIO_000904, SIO_000080, SIO_001194]]</td>\n",
       "      <td>[Feature_Influence_Explanation]</td>\n",
       "      <td>Quadratic_time</td>\n",
       "      <td>[[Ensemble_Method, OMIT_0001483, OMIT_0001480]...</td>\n",
       "      <td>[[Classification, InductiveTask], [Regression,...</td>\n",
       "      <td>[LightGBM, Sklearn, XGBoost]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Images/Anchors</td>\n",
       "      <td>_Images_Anchors_technique</td>\n",
       "      <td>[Anchor, SimplificationByRule_Extraction, Simp...</td>\n",
       "      <td>image</td>\n",
       "      <td>post-hoc</td>\n",
       "      <td>local</td>\n",
       "      <td>model-agnostic</td>\n",
       "      <td>prediction</td>\n",
       "      <td>[[SIO_000081, SIO_000080, SIO_001194]]</td>\n",
       "      <td>[Anchor_Explanation]</td>\n",
       "      <td>Quadratic_time</td>\n",
       "      <td>[[OMIT_0017046], [OMIT_0001480]]</td>\n",
       "      <td>[[Classification, InductiveTask]]</td>\n",
       "      <td>[Any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Tabular/IREX</td>\n",
       "      <td>_Tabular_IREX_technique</td>\n",
       "      <td>[ALE, Influence_Function, Feature_Relevance]</td>\n",
       "      <td>multivariate</td>\n",
       "      <td>post-hoc</td>\n",
       "      <td>global</td>\n",
       "      <td>modelSpecific</td>\n",
       "      <td>model</td>\n",
       "      <td>[[SIO_000904, SIO_000080, SIO_001194]]</td>\n",
       "      <td>[Feature_Influence_Explanation]</td>\n",
       "      <td>Linearithmic_time</td>\n",
       "      <td>[[OMIT_0017046], [OMIT_0001480]]</td>\n",
       "      <td>[[Classification, InductiveTask]]</td>\n",
       "      <td>[Any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Tabular/Importance</td>\n",
       "      <td>_Tabular_Importance_technique</td>\n",
       "      <td>[Feature_Relevance]</td>\n",
       "      <td>multivariate</td>\n",
       "      <td>post-hoc</td>\n",
       "      <td>global</td>\n",
       "      <td>model-agnostic</td>\n",
       "      <td>prediction</td>\n",
       "      <td>[[SIO_000904, SIO_000080, SIO_001194]]</td>\n",
       "      <td>[Feature_Influence_Explanation]</td>\n",
       "      <td>Quadratic_time</td>\n",
       "      <td>[[OMIT_0001480]]</td>\n",
       "      <td>[[Classification, InductiveTask], [Regression,...</td>\n",
       "      <td>[Any]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Tabular/DicePrivate</td>\n",
       "      <td>_Tabular_DicePrivate_technique</td>\n",
       "      <td>[DiCE, Optimisation_Based]</td>\n",
       "      <td>multivariate</td>\n",
       "      <td>post-hoc</td>\n",
       "      <td>local</td>\n",
       "      <td>model-agnostic</td>\n",
       "      <td>prediction</td>\n",
       "      <td>[[SIO_000419, SIO_000080, SIO_001194]]</td>\n",
       "      <td>[CounterfactualExplanation]</td>\n",
       "      <td>Quadratic_time</td>\n",
       "      <td>[[OMIT_0001480], [OMIT_0017046]]</td>\n",
       "      <td>[[Classification, InductiveTask]]</td>\n",
       "      <td>[TensorFlow1, TensorFlow2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Explainer            ExplainabilityTechnique  \\\n",
       "0  /Tabular/TreeSHAPGlobal  _Tabular_TreeSHAPGlobal_technique   \n",
       "1          /Images/Anchors          _Images_Anchors_technique   \n",
       "2            /Tabular/IREX            _Tabular_IREX_technique   \n",
       "3      /Tabular/Importance      _Tabular_Importance_technique   \n",
       "4     /Tabular/DicePrivate     _Tabular_DicePrivate_technique   \n",
       "\n",
       "                         ExplainabilityTechniqueType   DatasetType  \\\n",
       "0   [SHAP, Game_Theory_Technique, Feature_Relevance]  multivariate   \n",
       "1  [Anchor, SimplificationByRule_Extraction, Simp...         image   \n",
       "2       [ALE, Influence_Function, Feature_Relevance]  multivariate   \n",
       "3                                [Feature_Relevance]  multivariate   \n",
       "4                         [DiCE, Optimisation_Based]  multivariate   \n",
       "\n",
       "  Concurrentness   Scope     Portability  TargetType  \\\n",
       "0       post-hoc  global   modelSpecific       model   \n",
       "1       post-hoc   local  model-agnostic  prediction   \n",
       "2       post-hoc  global   modelSpecific       model   \n",
       "3       post-hoc  global  model-agnostic  prediction   \n",
       "4       post-hoc   local  model-agnostic  prediction   \n",
       "\n",
       "                               OutputType                  ExplanationType  \\\n",
       "0  [[SIO_000904, SIO_000080, SIO_001194]]  [Feature_Influence_Explanation]   \n",
       "1  [[SIO_000081, SIO_000080, SIO_001194]]             [Anchor_Explanation]   \n",
       "2  [[SIO_000904, SIO_000080, SIO_001194]]  [Feature_Influence_Explanation]   \n",
       "3  [[SIO_000904, SIO_000080, SIO_001194]]  [Feature_Influence_Explanation]   \n",
       "4  [[SIO_000419, SIO_000080, SIO_001194]]      [CounterfactualExplanation]   \n",
       "\n",
       "          Complexity                                       AIMethodType  \\\n",
       "0     Quadratic_time  [[Ensemble_Method, OMIT_0001483, OMIT_0001480]...   \n",
       "1     Quadratic_time                   [[OMIT_0017046], [OMIT_0001480]]   \n",
       "2  Linearithmic_time                   [[OMIT_0017046], [OMIT_0001480]]   \n",
       "3     Quadratic_time                                   [[OMIT_0001480]]   \n",
       "4     Quadratic_time                   [[OMIT_0001480], [OMIT_0017046]]   \n",
       "\n",
       "                                          AITaskType  \\\n",
       "0  [[Classification, InductiveTask], [Regression,...   \n",
       "1                  [[Classification, InductiveTask]]   \n",
       "2                  [[Classification, InductiveTask]]   \n",
       "3  [[Classification, InductiveTask], [Regression,...   \n",
       "4                  [[Classification, InductiveTask]]   \n",
       "\n",
       "                        Backend  \n",
       "0  [LightGBM, Sklearn, XGBoost]  \n",
       "1                         [Any]  \n",
       "2                         [Any]  \n",
       "3                         [Any]  \n",
       "4    [TensorFlow1, TensorFlow2]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb4faa",
   "metadata": {},
   "source": [
    "#### Getting similarities in natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "899305c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRow(df, explainer):\n",
    "    return df.loc[df['Explainer'] == explainer].values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83089d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimNL_simple_attr(attribute, e1_value, e2_value):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da878a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExplanationComplex(explainer1_atts, explainer2_atts, explanation_original, explanationToInclude, isBackend=False):\n",
    "    common_props = [x for x in explainer1_atts if x in explainer2_atts]\n",
    "    common_props_len = len(common_props)\n",
    "    if common_props_len > 0:\n",
    "        if isBackend==False:\n",
    "            explanation_original = explanation_original + explanationToInclude + common_props[0] + \", \"\n",
    "        else:\n",
    "            explanation_original = explanation_original + explanationToInclude + ','.join(common_props) + \", \"\n",
    "    return explanation_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5323c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExplanationComplexArray(explainer1_atts, explainer2_atts):\n",
    "    attributes_list = list()\n",
    "    for attrib_list1 in explainer1_atts:\n",
    "        for attrib_list2 in explainer2_atts:\n",
    "            common_props = [x for x in attrib_list1 if x in attrib_list2]\n",
    "            common_props_len = len(common_props)\n",
    "            if common_props_len > 0:\n",
    "                attributes_list.append(common_props[0])\n",
    "                \n",
    "    return list(set(attributes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "191568fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimNL(formatted_df, sim_matrix, explainer1, explainer2):\n",
    "    explanation = \"\"\n",
    "    explainer1_atts = getRow(formatted_df, explainer1)\n",
    "    explainer2_atts = getRow(formatted_df, explainer2)\n",
    "    if(sim_matrix[explainer1][explainer2] != 0):\n",
    "        # explanation about why they are similar\n",
    "        explanation = \"They are similar because \"\n",
    "        if explainer1_atts[3] == explainer2_atts[3]:\n",
    "            explanation = explanation + \"they can be applied to the same dataset type: \" + explainer2_atts[3] + \" data, \"\n",
    "        if explainer1_atts[4] == explainer2_atts[4]:\n",
    "            explanation = explanation + \"they have the same concurrentness: \" + explainer2_atts[4] + \", \"\n",
    "        if explainer1_atts[5] == explainer2_atts[5]:\n",
    "            explanation = explanation + \"they have the same scope: \" + explainer2_atts[5] + \", \"\n",
    "        if explainer1_atts[6] == explainer2_atts[6]:\n",
    "            explanation = explanation + \"they have the same portability: \" + explainer2_atts[6] + \", \"\n",
    "        if explainer1_atts[7] == explainer2_atts[7]:\n",
    "            explanation = explanation + \"they have the same target type: \" + explainer2_atts[7] + \", \"\n",
    "        if explainer1_atts[10] == explainer2_atts[10]:\n",
    "            explanation = explanation + \"they have the same computational complexity: \" + explainer2_atts[10] + \", \"\n",
    "        \n",
    "        # for the complex ones, if they share one in the array, show\n",
    "        # if they share more than one, show the most deep (the one in the beginning of the array)\n",
    "        explanationToInclude = \"they are the same explainability technique type: \"\n",
    "        explanation = getExplanationComplex(explainer1_atts[2], explainer2_atts[2], explanation, explanationToInclude)\n",
    "        explanationToInclude = \"they show the same explanation type: \"\n",
    "        explanation = getExplanationComplex(explainer1_atts[9], explainer2_atts[9], explanation, explanationToInclude)\n",
    "        explanationToInclude = \"they use the same backend: \"\n",
    "        explanation = getExplanationComplex(explainer1_atts[13], explainer2_atts[13], explanation, explanationToInclude, True)\n",
    "        \n",
    "        \n",
    "        attributes_list = getExplanationComplexArray(explainer1_atts[8], explainer2_atts[8])\n",
    "        if len(attributes_list) > 0:\n",
    "            explanation = explanation + \"they show the explanation with the same output type: \" + ','.join(attributes_list) + \", \"\n",
    "        attributes_list = getExplanationComplexArray(explainer1_atts[11], explainer2_atts[11])\n",
    "        if len(attributes_list) > 0:\n",
    "            explanation = explanation + \"they are applicable to the same AI method type: \" + ','.join(attributes_list) + \", \"\n",
    "        attributes_list = getExplanationComplexArray(explainer1_atts[12], explainer2_atts[12])\n",
    "        if len(attributes_list) > 0:\n",
    "            explanation = explanation + \"they are applicable to the same AI task type: \" + ','.join(attributes_list) + \", \"\n",
    "            \n",
    "    \n",
    "    #else:\n",
    "    #    explanation = \"They are not similar because they \"\n",
    "        # explanation about why they are not similar\n",
    "    #    if explainer1_atts[3] != explainer2_atts[3]:\n",
    "    #        explanation = explanation + \"are not applied to the same dataset type. \" + explainer1 + \" is applicable on \" + explainer1_atts[1] + \"data , while \" + explainer2 + \" is applicable on \" + explainer2_atts[1] + \" data\"\n",
    "    #    if explainer1_atts[6] != explainer2_atts[6]:\n",
    "    #        explanation = explanation + \"do not have the same portability. \" + explainer1 + \" is \" + explainer1_atts[6] + \", while \" + explainer2 + \" is \" + explainer2_atts[6]\n",
    "    #    if explainer1_atts[7] != explainer2_atts[7]:\n",
    "    #        explanation = explanation + \"do not have the same target type\" + explainer1 + \" has a\" + explainer1_atts[7] + \"as target type, while \" + explainer2 + \" has a\" + explainer2_atts[7] + \"as target type\"\n",
    "        \n",
    "    return explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a05a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(getRow(formatted_df, \"/Images/LIME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e33aacc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getSimNL(formatted_df, matrix, \"/Tabular/TreeSHAPGlobal\", \"/Tabular/ALE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b28c4613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They are similar because they can be applied to the same dataset type: image data, they have the same concurrentness: post-hoc, they have the same scope: local, they have the same portability: model-agnostic, they have the same target type: prediction, they have the same computational complexity: Quadratic_time, they are the same explainability technique type: Simplification, they use the same backend: Any, they show the explanation with the same output type: SIO_000081, they are applicable to the same AI method type: OMIT_0017046,OMIT_0001480, they are applicable to the same AI task type: Classification, '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSimNL(formatted_df, matrix, \"/Images/LIME\", \"/Images/Anchors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfbff93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
