{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e3362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from enum import Enum\n",
    "import os\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "import requests\n",
    "from utils import getPropertiesFormat\n",
    "\n",
    "#!pip install ipynb\n",
    "from ipynb.fs.full.CheckApplicability import applicabilityExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32941e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN='eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJfaWQiOiI2MmMyZjIwYmNmNzZkNzU1ZGNhOTU0ZWMiLCJjb21wYW55SWQiOiI2MmMyZjIwYmNmNzZkNzU1ZGNhOTU0ZWEiLCJpYXQiOjE2OTY0MzE0NzQsImV4cCI6MTY5NjUxNzg3NH0.VL_ke31M5IXTHOA8vUtZPo_kf_Kd1bFf7Qv1c0oTL84'\n",
    "CASE_ID=\"6411a8b641027bc15526a234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d435d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPERTIES_FILE = \"properties.csv\"\n",
    "SIMILARITIES_FILE = \"similarities.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae1b8117",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASURES = ['common_attributes', 'weighted_ca', 'cosine', 'depth', 'detail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e85645",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPERTIES = {}\n",
    "PROPERTIES['Explainer'] = 0\n",
    "PROPERTIES['ExplainerDescription'] = 1\n",
    "#PROPERTIES['ExplainabilityTechnique'] = 2\n",
    "PROPERTIES['ExplainabilityTechniqueType'] = 2\n",
    "PROPERTIES['DatasetType'] = 3\n",
    "PROPERTIES['ExplanationOutputType'] = 4\n",
    "PROPERTIES['ExplanationDescription'] = 5\n",
    "PROPERTIES['Concurrentness'] = 6\n",
    "PROPERTIES['Portability'] = 7\n",
    "PROPERTIES['Scope'] = 8\n",
    "PROPERTIES['TargetType'] = 9\n",
    "PROPERTIES['OutputType'] = 10\n",
    "PROPERTIES['Complexity'] = 11\n",
    "PROPERTIES['AIMethodType'] = 12\n",
    "PROPERTIES['AITaskType'] = 13\n",
    "PROPERTIES['Backend'] = 14\n",
    "PROPERTIES['metadata'] = 15\n",
    "\n",
    "SIMPLE_PROPERTIES = [PROPERTIES['DatasetType'], PROPERTIES['Concurrentness'], PROPERTIES['Scope'], PROPERTIES['Portability'], PROPERTIES['TargetType'], PROPERTIES['Complexity']]\n",
    "COMPLEX_PROPERTIES = [PROPERTIES['ExplainabilityTechniqueType'], PROPERTIES['ExplanationOutputType']]\n",
    "SIMPLE_MULT_PROPERTIES = [PROPERTIES['Backend']]\n",
    "COMPLEX_MULT_PROPERTIES = [PROPERTIES['OutputType'], PROPERTIES['AIMethodType'], PROPERTIES['AITaskType']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6987ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROP_WEIGHT = {}\n",
    "PROP_WEIGHT[PROPERTIES['ExplainabilityTechniqueType']] = 0.8\n",
    "PROP_WEIGHT[PROPERTIES['DatasetType']] = 1\n",
    "PROP_WEIGHT[PROPERTIES['Concurrentness']] = 0.7\n",
    "PROP_WEIGHT[PROPERTIES['Scope']] = 0.7\n",
    "PROP_WEIGHT[PROPERTIES['Portability']] = 1\n",
    "PROP_WEIGHT[PROPERTIES['TargetType']] = 1\n",
    "PROP_WEIGHT[PROPERTIES['OutputType']] = 0.5\n",
    "PROP_WEIGHT[PROPERTIES['ExplanationOutputType']] = 0.6\n",
    "PROP_WEIGHT[PROPERTIES['Complexity']] = 0.1\n",
    "PROP_WEIGHT[PROPERTIES['AIMethodType']] = 1\n",
    "PROP_WEIGHT[PROPERTIES['AITaskType']] = 1\n",
    "PROP_WEIGHT[PROPERTIES['Backend']] = 0.9\n",
    "PROP_WEIGHT[PROPERTIES['metadata']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e8996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.299999999999999\n"
     ]
    }
   ],
   "source": [
    "TOTAL_WEIGHT = 0\n",
    "for key in PROP_WEIGHT:\n",
    "    TOTAL_WEIGHT = TOTAL_WEIGHT + PROP_WEIGHT[key]\n",
    "\n",
    "print(TOTAL_WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc37f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllParents(list_parents):\n",
    "    \"\"\"\n",
    "        Function that creates a dictionary with each parent-children. \n",
    "        If they dont have childen, the list of children is empty\n",
    "    \"\"\"\n",
    "    my_parents = dict()\n",
    "    \n",
    "    for parent in list_parents:\n",
    "        my_parents[parent['label']] = []\n",
    "        if parent['children'] != []:\n",
    "            for child in parent['children']:\n",
    "                my_parents[parent['label']].append(child[\"label\"])\n",
    "            my_parents.update(getAllParents(parent['children']))\n",
    "                \n",
    "            \n",
    "    return my_parents\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19403975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKey(elem, parents):\n",
    "    return [x for x in parents if elem in parents[x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "399d0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchParents(elem, parents, my_parents, loop):\n",
    "    \"\"\"\n",
    "        # Look for the key where the element is\n",
    "        # do the same with the key until the last key doesnt appear in any children list\n",
    "    \"\"\"\n",
    "    next_parent = getKey(elem, parents)\n",
    "    if next_parent:\n",
    "        my_parents = my_parents + next_parent + searchParents(next_parent[0], parents, my_parents, loop)\n",
    "    else:\n",
    "        loop = False\n",
    "    return my_parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08280bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(elem, json_text,json_text_parents, explainability_technique_parents, explanation_type_parents, presentation_parents, ai_method_parents, ai_task_parents):\n",
    "    \"\"\"\n",
    "        Function that retrieves the labels \n",
    "    \"\"\"\n",
    "\n",
    "    #### PARENTS\n",
    "    tmp = elem[\"technique\"]\n",
    "    my_technique = json_text[\"ExplainabilityTechnique\"][tmp]\n",
    "    elem[\"technique\"] = [my_technique] + searchParents(my_technique, explainability_technique_parents, list(), True) \n",
    "    \n",
    "    \n",
    "    tmp = elem[\"dataset_type\"]\n",
    "    elem[\"dataset_type\"] = json_text[\"DatasetType\"][tmp]\n",
    "    \n",
    "    #### PARENTS\n",
    "    tmp = elem[\"explanation_type\"]\n",
    "    my_exp = json_text[\"Explanation\"][tmp]\n",
    "    elem[\"explanation_type\"] = [my_exp] + searchParents(my_exp, explanation_type_parents, list(), True)\n",
    "    \n",
    "    tmp = elem[\"concurrentness\"]\n",
    "    elem[\"concurrentness\"] = json_text[\"Concurrentness\"][tmp]\n",
    "    \n",
    "    tmp = elem[\"portability\"]\n",
    "    elem[\"portability\"] = json_text[\"Portability\"][tmp]\n",
    "    \n",
    "    tmp = elem[\"scope\"]\n",
    "    elem[\"scope\"] = json_text[\"Scope\"][tmp]\n",
    "    \n",
    "    tmp = elem[\"target\"]\n",
    "    elem[\"target\"] = json_text[\"Target\"][tmp]\n",
    "    \n",
    "    # parents + multiple selection\n",
    "    tmp = elem[\"presentations\"]\n",
    "    my_list = list()\n",
    "    for e in tmp:\n",
    "        label_e = json_text[\"InformationContentEntity\"][e]\n",
    "        my_list.append([label_e] + searchParents(label_e, presentation_parents, list(), True))\n",
    "    elem[\"presentations\"] = my_list\n",
    "      \n",
    "    tmp = elem[\"computational_complexity\"]\n",
    "    elem[\"computational_complexity\"] = json_text[\"ComputationalComplexity\"][tmp]\n",
    "    \n",
    "\n",
    "    tmp = elem[\"ai_methods\"]\n",
    "    my_list = list()\n",
    "    for e in tmp:\n",
    "        label_e = json_text[\"AIMethod\"][e]\n",
    "        my_list.append([label_e] + searchParents(label_e, ai_method_parents, list(), True))\n",
    "    elem[\"ai_methods\"] = my_list\n",
    "    \n",
    "    tmp = elem[\"ai_tasks\"]\n",
    "    my_list = list()\n",
    "    for e in tmp:\n",
    "        label_e = json_text[\"AITask\"][e]\n",
    "        my_list.append([label_e] + searchParents(label_e, ai_task_parents, list(), True))\n",
    "    elem[\"ai_tasks\"] = my_list\n",
    "    \n",
    "    \n",
    "    # multiple selection\n",
    "    tmp = elem[\"implementation\"]\n",
    "    my_list = list()\n",
    "    for e in tmp:\n",
    "        my_list.append(json_text[\"Implementation_Framework\"][e])\n",
    "    elem[\"implementation\"] = my_list\n",
    "    \n",
    "    return elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "185decec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettingMyExplainer(explainer_list, exp):\n",
    "    \"\"\"\n",
    "        Function to get the explainer just added to the ontology\n",
    "    \"\"\"\n",
    "    if explainer_list[-1][\"name\"]==exp:\n",
    "        #print(explainer_list[-1])\n",
    "        result = explainer_list[-1]\n",
    "    else:\n",
    "        for explainer in explainer_list:\n",
    "            if explainer[\"name\"]==exp:\n",
    "                #print(explainer)\n",
    "                result = explainer\n",
    "        print(\"Not found that explainer in the ontology\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37666c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_list(text, my_explainer):\n",
    "    #text = text.replace('\"','')\n",
    "    # every explainer\n",
    "    json_text = json.loads(text)\n",
    "    #print(json_text)\n",
    "    \n",
    "    info_my_explainer = [gettingMyExplainer(json_text, my_explainer)]\n",
    "    \n",
    "    # API call to get the labels\n",
    "    url = \"https://api-onto-dev.isee4xai.com/api/onto/cockpit/ExplainerFieldsFlat\"\n",
    "\n",
    "    payload={}\n",
    "    headers = {}\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    json_text_label = json.loads(response.text)\n",
    "    \n",
    "    # API call to get the explainer hierarchy\n",
    "    url = \"https://api-onto-dev.isee4xai.com/api/onto/cockpit/ExplainerFields\"\n",
    "\n",
    "    payload={}\n",
    "    headers = {}\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    json_text_parents = json.loads(response.text)\n",
    "    \n",
    "    # getting the parents for complex properties\n",
    "    explainability_technique_parents = getAllParents(json_text_parents['ExplainabilityTechnique']['children'])\n",
    "    explanation_type_parents = getAllParents(json_text_parents['Explanation']['children'])\n",
    "    presentation_parents = getAllParents(json_text_parents['InformationContentEntity']['children'])\n",
    "    ai_method_parents = getAllParents(json_text_parents['AIMethod']['children'])\n",
    "    ai_task_parents = getAllParents(json_text_parents['AITask']['children'])\n",
    "    \n",
    "    # for each explainer\n",
    "    #json_list = [getLabels(x,json_text_label,json_text_parents, explainability_technique_parents, explanation_type_parents, presentation_parents, ai_method_parents, ai_task_parents) for x in json_text]\n",
    "    json_list = [getLabels(x,json_text_label,json_text_parents, explainability_technique_parents, explanation_type_parents, presentation_parents, ai_method_parents, ai_task_parents) for x in info_my_explainer]\n",
    "    \n",
    "    df = json_normalize(json_list) \n",
    "    \n",
    "    #for key,vale in json_text.items():\n",
    "    df = df.drop('key', axis=1)\n",
    "    df.rename(columns={'name': 'Explainer', 'explainer_description':'ExplainerDescription', 'technique': 'ExplainabilityTechniqueType', 'dataset_type':'DatasetType', 'explanation_type':'ExplanationOutputType', 'explanation_description':'ExplanationDescription', 'concurrentness':'Concurrentness','portability':'Portability','scope':'Scope','target':'TargetType','presentations':'OutputType','computational_complexity':'Complexity','ai_methods':'AIMethodType','ai_tasks':'AITaskType', 'implementation':'Backend'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e057c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the explainers: https://api-onto-dev.isee4xai.com/api/explainers/list\n",
    "# Hierarchy: https://api-onto-dev.isee4xai.com/api/onto/cockpit/ExplainerFields\n",
    "# Labels flat: https://api-onto-dev.isee4xai.com/api/onto/cockpit/ExplainerFieldsFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60a7a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE TO CHECK A SPECIFIC USE CASE\n",
    "# url = \"https://api-dev.isee4xai.com/api/usecases/63d3f083bc0a2bb10eca948f\"\n",
    "\n",
    "# # access token???\n",
    "# payload={}\n",
    "# headers = {'X-Access-Token': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJfaWQiOiI2MmMyZjIwYmNmNzZkNzU1ZGNhOTU0ZWMiLCJjb21wYW55SWQiOiI2MmMyZjIwYmNmNzZkNzU1ZGNhOTU0ZWEiLCJpYXQiOjE2OTM5OTU2ODAsImV4cCI6MTY5NDA4MjA4MH0.vA8NWAmvzL5icI0yTLgOzswf1io5gz6y4b2ppaeAo6E'}\n",
    "\n",
    "# response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "178af0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettingExplainerProperties():\n",
    "    \"\"\"\n",
    "        Function that retrieves all the explainer properties\n",
    "    \"\"\"\n",
    "    df_fo = pd.read_csv(PROPERTIES_FILE, delimiter=',')\n",
    "    return df_fo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8aa57d",
   "metadata": {},
   "source": [
    "### Similarity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d89f9",
   "metadata": {},
   "source": [
    "- first one is only comparing the number of properties in common between the two explainers, it doesn't use infomration about parents and hierarchy in the ontology\n",
    "- second one is the same but using weights, so each property has a different importance. It uses information from parents in the ontology, but only checks if the parents are exactly the same or not, it doesn't take into account siblings. the hierarchical information is got for these properties: ExplanationType, ExplainabilityTechniqueType, Information Content Entity, AI MEthod, AI task, for the rest no, because those properties are \"simple\" \n",
    "- The rest of similarity metrics use hierarchical information taking into account also the siblings.\n",
    "- the third one is cosine and gets the similarity value for red properties according to: number of shared parents of the concept for both explainers/length of union of parents of the concept for both explainers\n",
    "- fourth one is depth: depth of shared parents of the concept for both explainers/max depth of the concept regarding both explainers \n",
    "- fifth one is detail: 1 - (1 / 2*(depth(e1_parents) + depth(e2_parents)))\n",
    "- the paper i used to inspire myself is this one (page 158) https://link.springer.com/content/pdf/10.1007/978-1-84628-666-7.pdf        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ef70d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_common_attributes(explainer1, explainer2):\n",
    "    \"\"\" Function that calculates the similarity between two explainers considering the number of attributes shared \"\"\"\n",
    "    #print(explainer1)\n",
    "    #print(explainer2)\n",
    "    \n",
    "    count = 0\n",
    "    if explainer1[PROPERTIES['Explainer']] == explainer2[PROPERTIES['Explainer']]: # if the explainer is the same\n",
    "        return 1\n",
    "    elif explainer1[PROPERTIES['DatasetType']] != explainer2[PROPERTIES['DatasetType']]:\n",
    "        return count\n",
    "    elif explainer1[PROPERTIES['ExplainabilityTechniqueType']] == explainer2[PROPERTIES['ExplainabilityTechniqueType']]: # if the explainability technique is the same\n",
    "        return 0.9\n",
    "    else:\n",
    "        i = 2\n",
    "        while i < len(explainer1):\n",
    "            if explainer1[i] == explainer2[i]:\n",
    "                count = count + 1\n",
    "            i = i + 1\n",
    "\n",
    "        return count/len(explainer1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "702543d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weighted_ca(explainer1, explainer2):\n",
    "    \"\"\" \n",
    "        Function that calculates the similarity between two explainers considering the number of attributes shared. \n",
    "        Each attribute has a weight\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    if explainer1[PROPERTIES['Explainer']] == explainer2[PROPERTIES['Explainer']]:\n",
    "        return 1\n",
    "    elif explainer1[PROPERTIES['DatasetType']] != explainer2[PROPERTIES['DatasetType']]:\n",
    "        return count \n",
    "    elif explainer1[PROPERTIES['ExplainabilityTechniqueType']] == explainer2[PROPERTIES['ExplainabilityTechniqueType']]: # if the explainability technique is the same\n",
    "        return 0.9   \n",
    "    else:\n",
    "        i = 2\n",
    "        while i < len(explainer1):\n",
    "            if explainer1[i] == explainer2[i]:\n",
    "                count = count + PROP_WEIGHT[i]\n",
    "            i = i + 1\n",
    "\n",
    "        return count/TOTAL_WEIGHT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85d1dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_cosine(e1_parents, e2_parents):\n",
    "    \"\"\"\n",
    "        it return a weight proportional to the parents the explainers share\n",
    "    \"\"\"\n",
    "    if e1_parents == e2_parents:\n",
    "        \n",
    "        return 1\n",
    "    else:\n",
    "        \n",
    "        shared = [x for x in e1_parents if x in e2_parents]\n",
    "        \n",
    "        return len(shared) / len(set(e1_parents + e2_parents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "811c13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_depth(e1_parents, e2_parents):\n",
    "    \"\"\"\n",
    "        it returns a weight according to the deep measure: \n",
    "        max depth of shared parents (expl1, expl2) / max(depth(expl1), depth(expl2))\n",
    "    \"\"\"\n",
    "    if e1_parents == e2_parents:\n",
    "        \n",
    "        return 1\n",
    "    else:\n",
    "        \n",
    "        LCS = len([x for x in e1_parents if x in e2_parents])\n",
    "        \n",
    "        denominator = max([len(e1_parents), len(e2_parents)])\n",
    "        \n",
    "        if denominator == 0 or LCS == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            \n",
    "            return (LCS)/denominator \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cf12ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_detail(e1_parents, e2_parents):\n",
    "    \"\"\"\n",
    "        it returns a weight according to the detail measure: \n",
    "        detail = 1 - (1 / 2*(len(explain1) + len(explain2))\n",
    "    \"\"\"\n",
    "    if e1_parents == e2_parents:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 - (1 / (2*(len(e1_parents) + len(e2_parents))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d1560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_onto(pos, e1_parents, e2_parents, measure):\n",
    "    \"\"\" Returns the weight for each attribute \"\"\"\n",
    "\n",
    "    if measure == \"cosine\":\n",
    "        return PROP_WEIGHT[pos] * get_parent_cosine(e1_parents, e2_parents)\n",
    "    elif measure == \"depth\":\n",
    "        return PROP_WEIGHT[pos] * get_parent_depth(e1_parents, e2_parents)\n",
    "    elif measure == \"detail\":\n",
    "        return PROP_WEIGHT[pos] * get_parent_detail(e1_parents, e2_parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17f85b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appy_measure_parents(explainer1, explainer2, measure):\n",
    "    \"\"\"\n",
    "        Auxiliar function to apply similarity metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    count = 0\n",
    "    if explainer1[PROPERTIES['Explainer']] == explainer2[PROPERTIES['Explainer']]:\n",
    "        return 1\n",
    "    elif explainer1[PROPERTIES['DatasetType']] != explainer2[PROPERTIES['DatasetType']]:\n",
    "        return count\n",
    "    elif explainer1[PROPERTIES['ExplainabilityTechniqueType']] == explainer2[PROPERTIES['ExplainabilityTechniqueType']]: # if the explainability technique is the same\n",
    "        return 0.9\n",
    "    else:\n",
    "        i = 2 \n",
    "        while i < len(explainer1):\n",
    "            if i in SIMPLE_PROPERTIES:\n",
    "                if explainer1[i] == explainer2[i]:\n",
    "                    count = count + PROP_WEIGHT[i]\n",
    "            elif i in COMPLEX_PROPERTIES:\n",
    "                explainer1_tmp = explainer1[i].replace('[','').replace(']','').replace(\"'\",\"\").split(', ')\n",
    "                explainer2_tmp = explainer2[i].replace('[','').replace(']','').replace(\"'\",\"\").split(', ')\n",
    "                count = count + weight_onto(i, explainer1_tmp, explainer2_tmp, measure)\n",
    "            elif i in SIMPLE_MULT_PROPERTIES:\n",
    "                # transform the string in a list and for each value, do the same we have in simple_properties\n",
    "                explainer1_tmp = explainer1[i].replace('[','').replace(']','').replace(\"'\",\"\").split(', ')\n",
    "                explainer2_tmp = explainer2[i].replace('[','').replace(']','').replace(\"'\",\"\").split(', ')\n",
    "                \n",
    "                if explainer1_tmp == ['Any'] or explainer2_tmp == ['Any']:\n",
    "                    count = count + (PROP_WEIGHT[i])\n",
    "                else:\n",
    "                    common_props = len([x for x in explainer1_tmp if x in explainer2_tmp]) \n",
    "                    union_props_tmp = [x for x in explainer2_tmp if x not in explainer1_tmp]\n",
    "                    union_props_tmp = union_props_tmp + explainer1_tmp\n",
    "                    union_props = len(union_props_tmp)\n",
    "\n",
    "                    if common_props != 0:\n",
    "                        count = count + (PROP_WEIGHT[i] * (common_props/union_props))\n",
    "            elif i in COMPLEX_MULT_PROPERTIES:\n",
    "                # transform the string in a list and for each value, do the same we have in complex properties\n",
    "                explainer1_tmp_x = explainer1[i][:-2].replace('[','').split('], ')\n",
    "                explainer1_tmp = [list(x.replace(\"'\",\"\").split(', ')) for x in explainer1_tmp_x]\n",
    "                \n",
    "                explainer2_tmp_x = explainer2[i][:-2].replace('[','').split('], ')\n",
    "                explainer2_tmp = [list(x.replace(\"'\",\"\").split(', ')) for x in explainer2_tmp_x]\n",
    "\n",
    "                common_props = len([x for x in explainer1_tmp if x in explainer2_tmp]) \n",
    "                union_props_tmp = [x for x in explainer2_tmp if x not in explainer1_tmp]\n",
    "                union_props_tmp = union_props_tmp + explainer1_tmp\n",
    "                union_props = len(union_props_tmp)\n",
    "                \n",
    "                weight_complex = 0\n",
    "                indx = True\n",
    "                for j in explainer1_tmp:\n",
    "                    for k in explainer2_tmp:\n",
    "                        weigth_tmp = (weight_onto(i, j, k, measure) * (common_props/union_props))\n",
    "                        \n",
    "                        if weigth_tmp != 0:\n",
    "                            if indx:\n",
    "                                weight_complex = weigth_tmp\n",
    "                                indx = False\n",
    "                            else:\n",
    "                                weight_complex = weight_complex * weigth_tmp\n",
    "                            \n",
    "                count = count + weight_complex\n",
    "            \n",
    "            \n",
    "            \n",
    "            i = i + 1\n",
    "        \n",
    "        # print(count)\n",
    "        return count/TOTAL_WEIGHT #len(explainer1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "771cfd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cosine(explainer1, explainer2):\n",
    "    \"\"\"\n",
    "        Function that calculates the similarity between two explainers considering the number of attributes shared. \n",
    "        Each attribute has a weight. Furthermore, we consider if the nodes are the same for the concepts \n",
    "        ExplanationType, ExplainabilityTechniqueType, Information Content Entity, AI MEthod, AI task.\n",
    "        If they are not, we look into their parent nodes in the ontology \n",
    "    \"\"\"\n",
    "    return appy_measure_parents(explainer1, explainer2, \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ba26a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appy_depth(explainer1, explainer2):\n",
    "    \"\"\"\n",
    "        Function that calculates the similarity between two explainers. In this case the concepts \n",
    "        ExplanationType, ExplainabilityTechniqueType, Information Content Entity, AI MEthod, AI task\n",
    "        are used to measure the depth of these concepts which is going to contribute to get the similarity value\n",
    "    \"\"\"\n",
    "    return appy_measure_parents(explainer1, explainer2, \"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "163139c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appy_detail(explainer1, explainer2):\n",
    "    \"\"\"\n",
    "        Function that calculates the similarity between two explainers with detail function for \n",
    "        ExplanationType, ExplainabilityTechniqueType, Information Content Entity, AI MEthod, AI task\n",
    "        detail = 1 - (1 / 2*(len(explain1) + len(explain2))\n",
    "    \"\"\"\n",
    "    return appy_measure_parents(explainer1, explainer2, \"detail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469cbe1",
   "metadata": {},
   "source": [
    "### Building the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e93d3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_measure(e1, e2, measure):\n",
    "     \n",
    "    \"\"\"\n",
    "        Function that returns similarity value with the measure\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # apply similarity measure to those explainers\n",
    "    if measure == 'common_attributes':\n",
    "        sim_result = apply_common_attributes(e1, e2)\n",
    "    elif measure == 'weighted_ca':\n",
    "        sim_result = apply_weighted_ca(e1, e2)\n",
    "    elif measure == 'cosine':\n",
    "        sim_result = apply_cosine(e1, e2)\n",
    "    elif measure == 'depth':\n",
    "        sim_result = appy_depth(e1, e2)\n",
    "    elif measure == 'detail':\n",
    "        sim_result = appy_detail(e1, e2)\n",
    "    \n",
    "        \n",
    "    return sim_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1216838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(df_data, explainers): #, e1):\n",
    "    \"\"\" This function receives the dataframe with all the data of all the explainers and the list of the explainers\"\"\"\n",
    "    \n",
    "    #for measure in MEASURES:\n",
    "    data = [] \n",
    "    for e1 in explainers:\n",
    "        for e2 in explainers:\n",
    "            e1_data = list(df_data.loc[df_data['Explainer'].isin([e1])].iloc[0])\n",
    "            e2_data = list(df_data.loc[df_data['Explainer'].isin([e2])].iloc[0])\n",
    "\n",
    "            sim = apply_measure(e1_data, e2_data, MEASURES[3]) # measure\n",
    "            data.append({'explainer': e1, 'e2': e2, 'sim': sim})\n",
    "\n",
    "    sim_matrix = pd.DataFrame(data)    \n",
    "    matrix = sim_matrix.pivot(index='explainer', columns='e2', values='sim')\n",
    "    matrix = matrix.fillna(0) \n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838931c",
   "metadata": {},
   "source": [
    "## Efficient code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17311405",
   "metadata": {},
   "source": [
    "- updateExplainerSimilarities(explainer_name) - explainer_name should be a string. Function to be called when inserting a new explainer in the ontology. The similarities between explainer is updated. \n",
    "- isExplainer(explainer_name) - explainer_name should be a string. Function to check if a node is an Explainer\n",
    "- getMostSimilarExplainer(explainer,k,critiques) - explainer should be a string, k an integer with the number of most similar explainer wanted. It returns the list in descending order (the most similar ones first). Critiques is the paremeter to include the critiques included by the user. If they dont include critiques, that should be {}. If they icnlude critiques, they have to include all the explainer properties in the dict, in this format: \n",
    "example1 = {'technique': [], 'dataset_type': '', 'explanation_type': [], 'concurrentness': [], 'scope': [], 'portability': [], 'target': [], 'presentations': [], 'computational_complexity': [], 'ai_methods': [], 'ai_tasks': [], 'implementation': []}\n",
    "It is important to note that in the lists, we have to put the URIS\n",
    "\n",
    "- getMostSimilarExplainerJSON(explainer,k,critiques) - It does the same than the previous one, but returning the result in json format {similar_explainer: sim_value}. Crtiques is the same than before, but in this case, the parameter could not be inclided, because by default is {}\n",
    "- getSimilarityValueExplainers(explainer1,explainer2) - explainer1 and explainer2 should be a string. It returns the similarity value between two explainers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "826e833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateExplainerSimilarities(explainer_name):\n",
    "    \"\"\"\n",
    "        Function to be called when creating a new explainer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting explainer\n",
    "    url = \"https://api-onto-dev.isee4xai.com/api/explainers/list\"\n",
    "    payload={}\n",
    "    headers = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    df_explainer = format_list(response.text, explainer_name)\n",
    "    \n",
    "    # update csv with properties\n",
    "    properties = pd.read_csv(PROPERTIES_FILE, delimiter=',') \n",
    "    \n",
    "    dataframes = [properties, df_explainer]\n",
    "    df_fo = pd.concat(dataframes)\n",
    "    \n",
    "    #print(df_fo)\n",
    "    \n",
    "    # PROPERTIES_FILE\n",
    "    df_fo.to_csv(PROPERTIES_FILE,index=False)\n",
    "    # trick to make the new explainer reading works when calculating the similarities\n",
    "    df_fo = pd.read_csv(PROPERTIES_FILE, delimiter=',') \n",
    "    \n",
    "    # update csv with similarities\n",
    "    # similarities = pd.read_csv('similarities_updated.csv') \n",
    "    \n",
    "    # get all the explainers already in the dataframe similarities + new explainer\n",
    "    explainers = df_fo[\"Explainer\"].tolist()\n",
    "    #all_explainers = explainers + [explainer_name]\n",
    "    \n",
    "    # create the similarities + create the dataframe \n",
    "    matrix = build_matrix(df_fo, explainers) #, explainer_name) #all_explainers\n",
    "    \n",
    "    # concat the old df and the new df\n",
    "    #result = pd.concat([similarities, matrix.reset_index()])\n",
    "        \n",
    "#     new_explainer = [float('nan')] * len(explainers) \n",
    "    \n",
    "#     result[\"prueba\"] = new_explainer + [1.0]\n",
    "#     result[\"prueba2\"] = new_explainer + [1.0]\n",
    "    # save the new dataframe in the similarities.csv\n",
    "    \n",
    "    # SIMILARITIES_FILE\n",
    "    matrix.reset_index().to_csv(SIMILARITIES_FILE,index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2469a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "updateExplainerSimilarities(\"/Tabular/PertCF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "534c0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isExplainer(elem):\n",
    "    \"\"\"\n",
    "        decide if the elem is an explainer in our library\n",
    "    \"\"\"\n",
    "    properties = pd.read_csv(PROPERTIES_FILE, delimiter=',') \n",
    "    explainers = properties[\"Explainer\"].tolist()\n",
    "    return elem in explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9707d743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isExplainer('/Tabular/PertCF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4287e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compareSimpleProperties(e1,e2):\n",
    "#     \"\"\"\n",
    "#         Function to know if two explainers share properties (plain)\n",
    "#     \"\"\"\n",
    "#     explainersEquals = False\n",
    "#     if e1[\"technique\"] == e2[\"technique\"] or e1[\"explanation_type\"] == e2[\"explanation_type\"] or e1[\"concurrentness\"] == e2[\"concurrentness\"] or e1[\"portability\"] == e2[\"portability\"] or e1[\"scope\"] == e2[\"scope\"] or e1[\"target\"] == e2[\"target\"] or e1[\"computational_complexity\"] == e2[\"computational_complexity\"]: \n",
    "#         explainersEquals = True\n",
    "#     return explainersEquals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1ef18a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def critiqueIsInExplainer(critiques, properties_explainer):\n",
    "    # If the property list is empty (or any for implementation), that explainer can be still on the list\n",
    "    if critiques == [] or critiques == [\"\"] or properties_explainer == ['Any'] or critiques == ['Any']:\n",
    "        return True\n",
    "    else:\n",
    "        my_shared_elems = [x for x in critiques if x in properties_explainer]\n",
    "        if my_shared_elems != []:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0341800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareListProperties(e1, e2):\n",
    "    \"\"\"\n",
    "        Function to know if two explainers share properties (in lists)\n",
    "        e2 is the critique - then, if the properties in e2 are in e1, we can get the explainer\n",
    "    \"\"\"\n",
    "    explainersEquals = False\n",
    "    \n",
    "    if critiqueIsInExplainer(e2[\"technique\"], e1[\"technique\"]) and critiqueIsInExplainer(e2[\"explanation_type\"], e1[\"explanation_type\"]) and critiqueIsInExplainer(e2[\"concurrentness\"], e1[\"concurrentness\"]) and critiqueIsInExplainer(e2[\"portability\"], e1[\"portability\"]) and critiqueIsInExplainer(e2[\"scope\"], e1[\"scope\"]) and critiqueIsInExplainer(e2[\"target\"], e1[\"target\"]) and critiqueIsInExplainer(e2[\"computational_complexity\"], e1[\"computational_complexity\"]) and critiqueIsInExplainer(e2[\"presentations\"], e1[\"presentations\"]) and critiqueIsInExplainer(e2[\"ai_methods\"], e1[\"ai_methods\"]) and critiqueIsInExplainer(e2[\"ai_tasks\"], e1[\"ai_tasks\"]) and critiqueIsInExplainer(e2[\"implementation\"], e1[\"implementation\"]):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "beaff5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExplainerCritiques(property_critiques):\n",
    "    \"\"\"\n",
    "        Function to get only the explainers that share the critiques indicated by the design user\n",
    "    \"\"\"\n",
    "    \n",
    "    explainers = getPropertiesFormat()\n",
    "    my_explainers = list()\n",
    "    for e, value in explainers.items():\n",
    "        if value[\"dataset_type\"] == property_critiques[\"dataset_type\"]:\n",
    "            if compareListProperties(value, property_critiques):\n",
    "                my_explainers.append(e)\n",
    "        \n",
    "    \n",
    "    # get only the explainers that includes the critiques (from PROPERTIES_FILE)\n",
    "    return my_explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a46b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = {'technique': [], 'dataset_type': 'Multivariate', 'explanation_type': [\"Counterfactual Explanation\"], 'concurrentness': [], 'scope': [], 'portability': [], 'target': ['Prediction'], 'presentations': [], 'computational_complexity': [], 'ai_methods': [], 'ai_tasks': [], 'implementation': ['Any'], 'metadata': '\"{\\\\n    \\\\\"supportsAPI\\\\\": true,\\\\n    \\\\\"supportsB&WImage\\\\\": false,\\\\n    \\\\\"needsData\\\\\": false,\\\\n    \\\\\"requiresAttributes\\\\\": []\\\\n}\"'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff12a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example1 = {'technique': [\"\"], 'dataset_type': 'http://www.w3id.org/iSeeOnto/explainer#multivariate', 'explanation_type': [\"https://purl.org/heals/eo#CounterfactualExplanation\"], 'concurrentness': [], 'scope': ['http://www.w3id.org/iSeeOnto/explainer#local'], 'portability': [], 'target': ['http://www.w3id.org/iSeeOnto/explainer#prediction'], 'presentations': [], 'computational_complexity': [], 'ai_methods': [], 'ai_tasks': [], 'implementation': ['http://www.w3id.org/iSeeOnto/explainer#Any'], 'metadata': '\"{\\\\n    \\\\\"supportsAPI\\\\\": true,\\\\n    \\\\\"supportsB&WImage\\\\\": false,\\\\n    \\\\\"needsData\\\\\": false,\\\\n    \\\\\"requiresAttributes\\\\\": []\\\\n}\"'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "957733cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Tabular/DicePrivate',\n",
       " '/Tabular/DicePublic',\n",
       " '/Tabular/DisCERN',\n",
       " '/Tabular/NICE',\n",
       " '/Tabular/PertCF']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getExplainerCritiques(example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3d00887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostSimilarExplainer(explainer,k,property_critiques):\n",
    "    \"\"\"\n",
    "        getting the k most similar explainer together with their similarity values\n",
    "    \"\"\"\n",
    "    matrix = pd.read_csv(SIMILARITIES_FILE, delimiter=',').set_index('explainer')\n",
    "    \n",
    "    # here get only the explainers that have the properties in property_critiques\n",
    "    if property_critiques != {}: # this measn the user has included critiques\n",
    "        # get all the explainers\n",
    "        explainers_critiques = getExplainerCritiques(property_critiques) \n",
    "        # filter matrix\n",
    "        matrix = matrix.loc[explainers_critiques]\n",
    "    \n",
    "    \n",
    "    my_explainer = matrix[explainer]\n",
    "    \n",
    "    explainer_values_sim = my_explainer.tolist()\n",
    "    explainer_list = my_explainer.index.tolist()\n",
    "    # check applicability of every explainer\n",
    "    matrix_explainer = [(explainer_list[i], explainer_values_sim[i]) for i in range(len(explainer_values_sim)) if ((explainer_values_sim[i] != 0) and (applicabilityExplainer(CASE_ID,ACCESS_TOKEN, explainer_list[i])[0] != False))]\n",
    "       \n",
    "    matrix_explainer_sorted = sorted(matrix_explainer, key=lambda x: x[1], reverse=True)\n",
    "       \n",
    "    return matrix_explainer_sorted[1:k+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0469cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostSimilarExplainerJSON(explainer,k,property_critiques={}):\n",
    "    \"\"\"\n",
    "        Transforming it in json format\n",
    "    \"\"\"\n",
    "    result = dict()\n",
    "    \n",
    "    for r in getMostSimilarExplainer(explainer,k,property_critiques):\n",
    "        result[r[0]] = r[1]  \n",
    "    \n",
    "    \n",
    "    return json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "102d2d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/Tabular/DicePublic', 0.3956310679611651),\n",
       " ('/Tabular/DisCERN', 0.3519417475728155)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostSimilarExplainer(\"/Tabular/DeepSHAPLocal\",6,example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5011381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/Tabular/IREX', 0.9),\n",
       " ('/Tabular/KernelSHAPGlobal', 0.7220873786407768),\n",
       " ('/Tabular/Importance', 0.6715210355987056)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostSimilarExplainer(\"/Tabular/ALE\",3,{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8016361c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"/Tabular/DicePublic\": 0.3956310679611651, \"/Tabular/DisCERN\": 0.3519417475728155}'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostSimilarExplainerJSON(\"/Tabular/DeepSHAPLocal\",6,example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef49743a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"/Tabular/IREX\": 0.9, \"/Tabular/KernelSHAPGlobal\": 0.7220873786407768, \"/Tabular/Importance\": 0.6715210355987056}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostSimilarExplainerJSON(\"/Tabular/ALE\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e41f8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilarityValueExplainers(explainer1,explainer2):\n",
    "    \"\"\"\n",
    "        Getting the similarity value between two explainers\n",
    "    \"\"\"\n",
    "    matrix = pd.read_csv(SIMILARITIES_FILE, delimiter=',').set_index('explainer')\n",
    "    return matrix[explainer1][explainer2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "661e67a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7220873786407768"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSimilarityValueExplainers(\"/Tabular/KernelSHAPGlobal\",\"/Tabular/ALE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7465ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc70c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
