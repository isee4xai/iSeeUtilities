Explainer,ExplainerDescription,ExplainabilityTechniqueType,DatasetType,ExplanationOutputType,ExplanationDescription,Concurrentness,Portability,Scope,TargetType,OutputType,Complexity,AIMethodType,AITaskType,Backend,metadata
/Tabular/LIME,"LIME perturbs the input data samples in order to train a simple model that approximates the prediction for the given instance and similar ones. The explanation contains the weight of each attribute to the prediction value. This method accepts 4 arguments: the 'id', the 'instance', the 'url'(optional),  and the 'params' dictionary (optiohnal) with the configuration parameters of the method. These arguments are described below.","['LIME', 'Simplification By Linear Regression', 'Simplification']",Multivariate,['Feature Influence Explanation'],"Explanation contains a plot with the most influent features for the given instance. For regression models, the plot displays both positive and negative contributions of each feature value to the predicted outcome. The same applies to classification models, but there can be a plot for each possible class. A table containing the feature values of the instance is also included.",Post-hoc,Model-agnostic,Local,Prediction,"[['chart', 'figure', 'media'], ['table', 'figure', 'media']]",Quadratic time,[['Machine Learning']],"[['Classification', 'Inductive Task'], ['Regression', 'Inductive Task']]","['PyTorch', 'Sklearn', 'TensorFlow 1', 'TensorFlow 2']","""{\n    \""supportsAPI\"": true,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Images/Anchors,"Uses anchors to find the groups of pixels that are sufficient for the model to justify the predicted class.This method accepts 5 arguments: the 'id', the 'url' (optional),  the 'params' dictionary (optional) with the configuration parameters of the method, the 'instance' containing the image that will be explained as a matrix, or the 'image' file instead. These arguments are described below.","['Anchor', 'Simplification By Rule Extraction', 'Simplification']",Image,"['Anchor Explanation', 'Feature Influence Explanation']",Explanation displays the pixels that are sufficient for the model to justify the outcome,Post-hoc,Model-agnostic,Local,Prediction,"[['image', 'figure', 'media']]",Quadratic time,[['Machine Learning']],"[['Classification', 'Inductive Task']]",['Any'],"""{\n    \""supportsAPI\"": true,\n    \""supportsB&WImage\"": true,\n    \""needsData\"": false,\n    \""requiresAttributes\"": []\n}"""
/Images/Counterfactuals,"Finds an image that is similar to the original, but that the model predicts to be from a different class. The class of the conterfactual can be explicitly specified.This method accepts 5 arguments: the 'id', the 'url' (optional),  the 'params' dictionary (optional) with the configuration parameters of the method, the 'instance' containing the image that will be explained as a matrix, or the 'image' file instead. These arguments are described below.","['Wachter', 'Optimisation Based']",Image,['Counterfactual Explanation'],Explanation displays an image that is as similar as possible to the original but that the model predicts to be from a different class.,Post-hoc,Model-agnostic,Local,Prediction,"[['image', 'figure', 'media']]",Quadratic time,"[['Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task']]",['TensorFlow 2'],"""{\n    \""supportsAPI\"": true,\n    \""supportsB&WImage\"": true,\n    \""needsData\"": false,\n    \""requiresAttributes\"": []\n}"""
/Images/GradCamTorch,"Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting important regions in the image for predicting the concept.This method accepts 4 arguments: the 'id', the 'params' dictionary (optional) with the configuration parameters of the method, the 'instance' containing the image that will be explained as a matrix, or the 'image' file instead. These arguments are described below.","['Wachter', 'Optimisation Based']",Image,"['Saliency Map', 'Feature Influence Explanation']",Explanation displays an image that highlights the region that contributes the most to the outcome.,Post-hoc,Model-specific,Local,Prediction,"[['image', 'figure', 'media']]",Linearithmic time,"[['Neural Networks (Computer)', 'Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task']]",['PyTorch'],"""{\n    \""supportsAPI\"": false,\n    \""needsData\"": false,\n    \""supportsB&WImage\"": false,\n    \""requiresAttributes\"": [\n        {\n            \""target_layer\"": \""name of target layer to be provided as a string. This is the layer that you want to compute the visualization for. Usually this will be the last convolutional layer in the model. It is also possible to specify internal components of this layer by         passing the target_layer_index parameter in params when making a call to the explainer resource. To get the target layer, this method executes 'model.<target_layer>        [<target_layer_index>]' \\nSome common examples of these parameters for well-known models:\\nResnet18 and 50: model.layer4 -> 'target_layer':'layer4'\\nVGG, densenet161: model.features[-1] -> 'target_layer':'features', 'target_layer_index':-1\\nmnasnet1_0: model.layers[-1] -> 'target_layer':'layers', 'target_layer_index':-1\""\n        }\n    ]\n}"""
/Images/LIME,"Uses LIME to identify the group of pixels that contribute the most to the predicted class.This method accepts 5 arguments: the 'id', the 'url' (optional),  the 'params' dictionary (optional) with the configuration parameters of the method, the 'instance' containing the image that will be explained as a matrix, or the 'image' file instead. These arguments are described below.","['LIME', 'Simplification By Linear Regression', 'Simplification']",Image,['Feature Influence Explanation'],Explanation displays the group of pixels that contribute positively (in green) and negatively (in red) to the prediction of the image class. More than one class may be displayed.,Post-hoc,Model-agnostic,Local,Prediction,"[['image', 'figure', 'media']]",Quadratic time,"[['Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task']]","['PyTorch', 'Sklearn', 'TensorFlow 1', 'TensorFlow 2']","""{\n    \""supportsAPI\"": true,\n    \""supportsB&WImage\"": false,\n    \""needsData\"": false,\n    \""requiresAttributes\"": []\n}"""
/Tabular/ALE,"Computes the accumulated local effects (ALE) of a model for the specified features. This method accepts 3 arguments: the 'id', the 'url',  and the 'params' JSON with the configuration parameters of the method. These arguments are described below.","['ALE', 'Influence Function', 'Feature Relevance']",Multivariate,['Feature Influence Explanation'],Explanation presenrs a plot for each of the specified features where the y-axis represents the global feature effect on the outcome value according to the computed ALE values.,Post-hoc,Model-agnostic,Global,Model,"[['chart', 'figure', 'media']]",Linearithmic time,"[['Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task'], ['Regression', 'Inductive Task']]",['Any'],"""{\n    \""supportsAPI\"": true,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Tabular/Anchors,"Anchors provide local explanations in the form of simple boolean rules with a precision score and a coverage value which represents the scope in which that rules applies to similar instances. This method accepts 4 arguments: the 'id', the 'instance', the 'url' (optional),  and the 'params' JSON (optional) with the configuration parameters of the method. These arguments are described below.","['Anchor', 'Simplification By Rule Extraction', 'Simplification']",Multivariate,"['Anchor Explanation', 'Feature Influence Explanation']","Explanation displays an instance with the boolean rule (anchor) that was found, and values for its precision and coverage (scope in which that rules applies to similar instances).	",Post-hoc,Model-agnostic,Local,Prediction,"[['chart', 'figure', 'media'], ['textual entity', 'language entity']]",Quadratic time,"[['Supervised Machine Learning', 'Machine Learning'], ['Machine Learning']]","[['Classification', 'Inductive Task']]",['Any'],"""{\n    \""supportsAPI\"": true,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Tabular/DicePrivate,"Diverse Counterfactual Explanations (DiCE)  private method generates counterfactuals without training data. However, it requires the format and ranges of the data to be specified when uploading the model. This method is currently supported for TensorFlow models only.  Accepts 3 arguments: the 'id' string, the 'instance', and the 'params' dictionary (optional) containing the configuration parameters of the explainer. These arguments are described below.","['DiCE', 'Optimisation Based']",Multivariate,['Counterfactual Explanation'],Explanation contains a table with the original instance compared against a generated couterfactual(s).,Post-hoc,Model-agnostic,Local,Prediction,"[['table', 'figure', 'media']]",Quadratic time,"[['Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task']]","['TensorFlow 1', 'TensorFlow 2']","""{\n    \""supportsAPI\"": false,\n    \""needsData\"": false,\n    \""requiresAttributes\"": [\n        {\n            \""features\"": \""Dictionary with feature names as keys and arrays containing the ranges of continuous features, or strings with the categories for categorical features.\""\n        }\n    ]\n}"""
/Tabular/DicePublic,"Diverse Counterfactual Explanations (DiCE) public method generates counterfactuals using the ML model's training data as a baseline. Accepts 3 arguments: the 'id' string, the 'instance', and the 'params' dictionary (optional) containing the configuration parameters of the explainer. These arguments are described below.","['DiCE', 'Optimisation Based']",Multivariate,['Counterfactual Explanation'],Explanation contains a table with the original instance compared against a generated couterfactual(s).,Post-hoc,Model-agnostic,Local,Prediction,"[['table', 'figure', 'media']]",Quadratic time,"[['Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task']]","['PyTorch', 'Sklearn', 'TensorFlow 1', 'TensorFlow 2']","""{\n    \""supportsAPI\"": false,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Tabular/DisCERN,"Discovering Counterfactual Explanations using Relevance Features from Neighbourhoods (DisCERN) generates counterfactuals for scikit-learn-based models. Requires 3 arguments: the 'id' string, the 'instance' to be explained, and the 'params' object containing the configuration parameters of the explainer. These arguments are described below.","['DisCERN', 'Data-driven']",Multivariate,['Counterfactual Explanation'],Explanation contains a table with the original instance compared against a generated couterfactual(s).,Post-hoc,Model-agnostic,Local,Prediction,"[['table', 'figure', 'media']]",Quadratic time,"[['Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task']]",['Sklearn'],"""{\n    \""supportsAPI\"": false,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Tabular/Importance,"This method measures the increase in the prediction error of the model after the feature's values are randomly permuted. A feature is considered important if the error of the model increases significantly when permuting it. Accepts 2 arguments: the 'id' string, and the 'params' object (optional) containing the configuration parameters of the explainer. These arguments are described below.",['Feature Relevance'],Multivariate,['Feature Influence Explanation'],Explanation contains a bar plot representing the increase in the prediction error (importance) for the features with the highest values.,Post-hoc,Model-agnostic,Global,Prediction,"[['chart', 'figure', 'media']]",Quadratic time,"[['Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task'], ['Regression', 'Inductive Task']]",['Any'],"""{\n    \""supportsAPI\"": false,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Tabular/DeepSHAPGlobal,"This method based on Shapley values computes the average contribution of each feature for the whole training dataset. DeepSHAP is intended for TensorFlow/Keras models only. This method accepts 2 arguments: the 'id', and the 'params' JSON with the configuration parameters of the method. These arguments are described below.","['SHAP', 'Game Theory Technique', 'Feature Relevance']",Multivariate,['Feature Influence Explanation'],"Explanation presents a beeswarm plot that is designed to display an information-dense summary of how the top features in a dataset impact the model output. Each instance the given explanation is represented by a single dot on each feature fow. The x position of the dot is determined by the SHAP value of that feature, and dots 'pile up' along each feature row to show density. Color is used to display the original value of a feature.",Post-hoc,Model-specific,Global,Prediction,"[['chart', 'figure', 'media'], ['plot', 'figure part', 'media']]",Quadratic time,"[['Neural Networks (Computer)', 'Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task'], ['Regression', 'Inductive Task']]","['TensorFlow 1', 'TensorFlow 2']","""{\n    \""supportsAPI\"": true,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Tabular/DeepSHAPLocal,"This method displays the contribution of each attribute for an individual prediction based on Shapley values (for tree ensemble methods only). Supported for XGBoost, LightGBM, CatBoost, scikit-learn and pyspark tree models. This method accepts 3 arguments: the 'id', the 'instance', and the 'params' dictionary (optional) with the configuration parameters of the method. These arguments are described below.","['SHAP', 'Game Theory Technique', 'Feature Relevance']",Multivariate,['Feature Influence Explanation'],"Explanation presents a waterfall plot. The bottom of a waterfall plot starts as the expected value of the model output, and then each row shows how the positive (red) or negative (blue) contribution of each feature moves the value from the expected model output over the background dataset to the model output for this prediction.",Post-hoc,Model-specific,Local,Prediction,"[['chart', 'figure', 'media'], ['plot', 'figure part', 'media']]",Quadratic time,"[['Neural Networks (Computer)', 'Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task'], ['Regression', 'Inductive Task']]","['TensorFlow 1', 'TensorFlow 2']","""{\n    \""supportsAPI\"": true,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Tabular/KernelSHAPLocal,"This method displays the contribution of each attribute for an individual prediction based on Shapley values. This method accepts 4 arguments: the 'id', the 'instance', the 'url' (optional),  and the 'params' dictionary (optional) with the configuration parameters of the method. These arguments are described below.","['SHAP', 'Game Theory Technique', 'Feature Relevance']",Multivariate,['Feature Influence Explanation'],"Explanation presents a waterfall plot. The bottom of a waterfall plot starts as the expected value of the model output, and then each row shows how the positive (red) or negative (blue) contribution of each feature moves the value from the expected model output over the background dataset to the model output for this prediction.",Post-hoc,Model-agnostic,Local,Prediction,"[['chart', 'figure', 'media'], ['plot', 'figure part', 'media']]",Exponential time,"[['Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task'], ['Regression', 'Inductive Task']]",['Any'],"""{\n    \""supportsAPI\"": true,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Tabular/KernelSHAPGlobal,"This method based on Shapley values computes the average contribution of each feature for the whole training dataset. This method accepts 3 arguments: the 'id', the 'url',  and the 'params' JSON with the configuration parameters of the method. These arguments are described below.","['SHAP', 'Game Theory Technique', 'Feature Relevance']",Multivariate,['Feature Influence Explanation'],"Explanation presents a beeswarm plot that is designed to display an information-dense summary of how the top features in a dataset impact the model output. Each instance the given explanation is represented by a single dot on each feature fow. The x position of the dot is determined by the SHAP value of that feature, and dots 'pile up' along each feature row to show density. Color is used to display the original value of a feature.",Post-hoc,Model-agnostic,Global,Model,"[['chart', 'figure', 'media'], ['plot', 'figure part', 'media']]",Exponential time,"[['Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task'], ['Regression', 'Inductive Task']]",['Any'],"""{\n    \""supportsAPI\"": true,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Tabular/TreeSHAPGlobal,"This method based on Shapley values computes the average contribution of each feature for the whole training dataset. TreeSHAP is intended for ensemble methods only and is currently supported for XGBoost, LightGBM, CatBoost, scikit-learn and pyspark tree models. This method accepts 2 arguments: the 'id', and the 'params' JSON with the configuration parameters of the method. These arguments are described below.","['SHAP', 'Game Theory Technique', 'Feature Relevance']",Multivariate,['Feature Influence Explanation'],"Explanation presents a beeswarm plot that is designed to display an information-dense summary of how the top features in a dataset impact the model output. Each instance the given explanation is represented by a single dot on each feature fow. The x position of the dot is determined by the SHAP value of that feature, and dots 'pile up' along each feature row to show density. Color is used to display the original value of a feature.	",Post-hoc,Model-specific,Global,Model,"[['chart', 'figure', 'media'], ['plot', 'figure part', 'media']]",Quadratic time,"[['Ensemble Method', 'Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task'], ['Regression', 'Inductive Task']]","['LightGBM', 'Sklearn', 'XGBoost']","""{\n    \""supportsAPI\"": true,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Tabular/TreeSHAPLocal,"This method displays the contribution of each attribute for an individual prediction based on Shapley values (for tree ensemble methods only). Supported for XGBoost, LightGBM, CatBoost, scikit-learn and pyspark tree models. This method accepts 3 arguments: the 'id', the 'instance', and the 'params' JSON with the configuration parameters of the method. These arguments are described below.","['SHAP', 'Game Theory Technique', 'Feature Relevance']",Multivariate,['Feature Influence Explanation'],"Explanation presents a waterfall plot. The bottom of a waterfall plot starts as the expected value of the model output, and then each row shows how the positive (red) or negative (blue) contribution of each feature moves the value from the expected model output over the background dataset to the model output for this prediction.",Post-hoc,Model-specific,Local,Prediction,"[['chart', 'figure', 'media'], ['plot', 'figure part', 'media']]",Quadratic time,"[['Ensemble Method', 'Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task'], ['Regression', 'Inductive Task']]","['LightGBM', 'Sklearn', 'XGBoost']","""{\n    \""supportsAPI\"": true,\n    \""needsData\"": false,\n    \""requiresAttributes\"": []\n}"""
/Tabular/NICE,"NICE is an algorithm to generate Counterfactual Explanations for heterogeneous tabular data.NICE exploits information from a nearest instance to speed up the search process and guarantee that an explanation will be found. Accepts 4 arguments: the 'id' string, the 'instance', the 'url' (optional), and the 'params' dictionary (optional) containing the configuration parameters of the explainer. These arguments are described below.","['Wachter', 'Optimisation Based']",Multivariate,['Counterfactual Explanation'],Explanation contains a table with the original instance compared against a generated couterfactual(s).,Post-hoc,Model-agnostic,Local,Prediction,"[['table', 'figure', 'media']]",Linearithmic time,"[['Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task']]",['Any'],"""{\n    \""supportsAPI\"": true,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Text/LIME,"LIME perturbs the input data samples in order to train a simple model that approximates the prediction for the given instance and similar ones. The explanation contains the weight of each word to the prediction value. This method accepts 4 arguments: the 'id', the 'instance', the 'url',  and the 'params' JSON with the configuration parameters of the method. These arguments are described below.","['LIME', 'Simplification By Linear Regression', 'Simplification']",Text,['Feature Influence Explanation'],"Explanation is a plot with the most influent words for the given instance. For regression models, the plot displays both positive and negative contributions of each word to the predicted outcome. The same applies to classification models, but there can be a plot for each possible class. The text instance with highlighted words is also included.",Post-hoc,Model-agnostic,Local,Prediction,"[['chart', 'figure', 'media']]",Linearithmic time,"[['Supervised Machine Learning', 'Machine Learning'], ['Natural Language Processing']]","[['Classification', 'Inductive Task']]",['Any'],"""{\n    \""supportsAPI\"": true,\n    \""needsData\"": false,\n    \""requiresAttributes\"": []\n}"""
/Images/IntegratedGradients,"Defines an attribution value for each pixel in the image provided based on the Integration Gradients method. It only works with Tensorflow/Keras models.This method accepts 4 arguments: the 'id', the 'params' dictionary (optional) with the configuration parameters of the method, the 'instance' containing the image that will be explained as a matrix, or the 'image' file that can be passed instead of the instance. These arguments are described below.","['Integrated Gradient Technique', 'Gradient-based Technique', 'Feature Relevance']",Image,"['Contrasting Feature Importance Explanation', 'Feature Influence Explanation']",Subplot with four columns. The first column shows the original image and its prediction. The second column shows the values of the attributions for the target class. The third column shows the positive valued attributions. The fourth column shows the negative valued attributions.,Post-hoc,Model-class specific,Local,Prediction,"[['heatmap', 'chart', 'figure', 'media']]",Quadratic time,"[['Neural Networks (Computer)', 'Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task']]","['TensorFlow 1', 'TensorFlow 2']","""{\n    \""supportsAPI\"": false,\n    \""supportsB&WImage\"": true,\n    \""needsData\"": false,\n    \""requiresAttributes\"": []\n}"""
/Tabular/IREX,"IREX is a reusable method for the Iterative Refinement and EXplanation of classification models. It has been designed for domain-expert users -without machine learning skills- that need to understand and improve classification models. This particular implementation of IREX uses ALE to identify anomalous features that may be contradictory to what the expert knowledge indicates. Anomalous features are highlighted in red in an ALE heatmap. This method accepts 3 arguments: the 'id', the 'url',  and the 'params' JSON with the configuration parameters of the method. These arguments are described below.","['ALE', 'Influence Function', 'Feature Relevance']",Multivariate,['Feature Influence Explanation'],"A heatmap displaying the relevance of the features according to ALE, where anomalous features (behavior differring from expected values) are highlighted in red.",Post-hoc,Model-specific,Global,Model,"[['chart', 'figure', 'media']]",Linearithmic time,[['Machine Learning']],"[['Classification', 'Inductive Task']]",['Any'],"""{\n    \""supportsAPI\"": false,\n    \""needsData\"": true,\n    \""requiresAttributes\"": []\n}"""
/Text/NLPClassifier,An explainer for NLP classification models. ,['Data-driven'],Text,['Feature Influence Explanation'],"The explanation shows the confidence scores for the possible classes of the text classified. The explanation also shows the top keywords used in the query with the TF-IDF score, the top keywords used in similar texts per class, and the overlapping words with similar texts for each class.",Post-hoc,Model-specific,Local,Prediction,"[['textual entity', 'language entity'], ['table', 'figure', 'media']]",Quadratic time,"[['Natural Language Processing'], ['Machine Learning']]","[['Multi-class Classification', 'Classification', 'Inductive Task']]",['Sklearn'],"""{\n    \""supportsAPI\"": false,\n    \""needsData\"": false,\n    \""requiresAttributes\"": []\n}"""
/Timeseries/CBRFox,"This method applies the Case-Based Reasoning paradigm to provide explanations-by-example, where time series are split into different time-window cases that serveas explanation cases for the outcome of the prediction model. It has been designed for domain-expert users -without ML skills- that need to understand and how (future)predictions could be dependent of past time series windows. It proposes a novel similarity function which deals with both the morphological similarity and the absoluteproximity between the time series, together with several reuse strategies to generate the explanation cases. It uses an automatic evaluation approach based on computingthe error (MAE) between the model prediction for and the actual values in the solution of the explanatory case. Finally, this evaluation method is applied to demonstratethe performance of the proposal on the given dataset. This method accepts 3 arguments: the 'id', the 'instance',  and the 'params' dictionary (optional) with the configuration parameters of the method. These arguments are described below.",['Knowledge Extraction'],Time series,['Case Based Explanation'],"The explanation shown is an explanation-by-example where users can watch charts comparing meteorogical features between the case to explain and its most similar case, or between the case and its least similar case. ",Post-hoc,Model-agnostic,Local,Prediction,"[['chart', 'figure', 'media']]",Quadratic time,"[['Natural Language Processing'], ['Machine Learning']]","[['Forecasting', 'Inductive Task']]",['Any'],"""{\n    \""supportsAPI\"": false,\n    \""needsData\"": true,\n    \""requiresAttributes\"": [\n        {\n            \""target_columns\"": \""Array containing the indexes of the target columns of the dataset.\""\n        }\n    ]\n}"""
/Images/GradCam,"Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting important regions in the image for predicting the concept.This method accepts 4 arguments: the 'id', the 'params' dictionary (optional) with the configuration parameters of the method, the 'instance' containing the image that will be explained as a matrix, or the 'image' file instead. These arguments are described below.","['GradCam Technique', 'Gradient-based Technique', 'Feature Relevance']",Image,"['Saliency Map', 'Feature Influence Explanation']",Explanation displays an image that highlights the region that contributes the most to the outcome.,Post-hoc,Model-specific,Local,Prediction,"[['image', 'figure', 'media']]",Linearithmic time,"[['Neural Networks (Computer)', 'Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task']]","['PyTorch', 'TensorFlow 1', 'TensorFlow 2']","""{\n    \""supportsAPI\"": false,\n    \""needsData\"": false,\n    \""supportsB&WImage\"": false,\n    \""requiresAttributes\"": [\n        {\n            \""target_layer\"": \""name of target layer to be provided as a string. This is the layer that you want to compute the visualization for. Usually this will be the last convolutional layer in the model. It is also possible to specify internal components of this layer by         passing the target_layer_index parameter in params when making a call to the explainer resource. To get the target layer, this method executes 'model.<target_layer>        [<target_layer_index>]' \\nSome common examples of these parameters for well-known models:\\nResnet18 and 50: model.layer4 -> 'target_layer':'layer4'\\nVGG, densenet161: model.features[-1] -> 'target_layer':'features', 'target_layer_index':-1\\nmnasnet1_0: model.layers[-1] -> 'target_layer':'layers', 'target_layer_index':-1\""\n        }\n    ]\n}"""
/Images/NearestNeighbours,Finds the nearest neighbours to a data instances based on minimum euclidean distance,['Data-driven'],Image,['Neighbourhood Explanation'],This explanation presents nearest neighbours to the query; nearest neighbours are examples that are similar to the query with similar AI system outcomes.,Post-hoc,Model-class specific,Local,Prediction,"[['image', 'figure', 'media']]",Exponential time,"[['Neural Networks (Computer)', 'Supervised Machine Learning', 'Machine Learning']]","[['Classification', 'Inductive Task'], ['Regression', 'Inductive Task']]","['PyTorch', 'TensorFlow 1', 'TensorFlow 2']","""{\n    \""supportsAPI\"": true,\n    \""supportsB&WImage\"": false,\n    \""needsData\"": false,\n    \""requiresAttributes\"": []\n}"""
/Misc/AIModePerformance,Rule based explainer that extracts the performance metrics from case structure representation of the use case.,['Knowledge Extraction'],Image,['Statistical Explanation'],This explanation presents the perfromance metrics of the AI System.,Post-hoc,Model-agnostic,Global,Model,"[['table', 'figure', 'media']]",Constant time,"[['Supervised Machine Learning', 'Machine Learning']]",[['Inductive Task']],['Any'],"""{\n    \""supportsAPI\"": true,\n    \""needsData\"": false,\n    \""requiresAttributes\"": []\n}"""
/Misc/AIModelPerformance,Rule based explainer that extracts the performance metrics from case structure representation of the use case.,['Data-driven'],Multivariate,['Statistical Explanation'],This explanation presents the perfromance metrics of the AI System.,Post-hoc,Model-agnostic,Global,Model,"[['table', 'figure', 'media']]",Constant time,"[['Supervised Machine Learning', 'Machine Learning']]",[['Inductive Task']],['Any'],"""{\n    \""supportsAPI\"": true,\n    \""needsData\"": false,\n    \""requiresAttributes\"": []\n}"""
